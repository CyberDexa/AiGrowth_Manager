"""
Test Database Performance Optimizations

Verify indexes, connection pooling, and query caching are working.
"""
import sys
import os
import time
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import text
from app.db.database import engine, SessionLocal
from app.core.query_cache import analytics_cache, QueryCache


def test_indexes():
    """Test that performance indexes exist"""
    print("=" * 60)
    print("Testing Database Indexes")
    print("=" * 60)
    
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT tablename, indexname, indexdef 
            FROM pg_indexes 
            WHERE schemaname = 'public' 
            AND indexname LIKE 'idx_%' 
            ORDER BY tablename, indexname
        """))
        
        indexes = list(result)
        
        if indexes:
            print(f"\n‚úÖ Found {len(indexes)} custom indexes:\n")
            for row in indexes:
                table, index_name, _ = row
                print(f"   {table:25} ‚Üí {index_name}")
            
            # Expected indexes
            expected = [
                'idx_published_posts_business_published_desc',
                'idx_published_posts_platform_published',
                'idx_social_accounts_business_platform_active',
                'idx_social_accounts_platform_user'
            ]
            
            index_names = [row[1] for row in indexes]
            missing = [idx for idx in expected if idx not in index_names]
            
            if missing:
                print(f"\n‚ö†Ô∏è  Missing expected indexes:")
                for idx in missing:
                    print(f"   - {idx}")
                return False
            else:
                print(f"\n‚úÖ All expected indexes exist")
                return True
        else:
            print("‚ùå No custom indexes found")
            return False


def test_connection_pooling():
    """Test connection pooling configuration"""
    print("\n" + "=" * 60)
    print("Testing Connection Pooling")
    print("=" * 60)
    
    try:
        pool = engine.pool
        print(f"\n‚úÖ Pool class: {pool.__class__.__name__}")
        print(f"‚úÖ Pool size: {pool.size()}")
        print(f"‚úÖ Max overflow: {pool._max_overflow}")
        print(f"‚úÖ Timeout: {pool._timeout}s")
        print(f"‚úÖ Pool recycle: {pool._recycle}s")
        print(f"‚úÖ Pool pre-ping: {pool._pre_ping}")
        
        # Test getting connections
        print(f"\nüìä Connection pool status:")
        print(f"   Checked out: {pool.checkedout()}")
        print(f"   Available: {pool.size() - pool.checkedout()}")
        
        # Test creating multiple connections
        print(f"\nüîÑ Testing connection checkout...")
        connections = []
        for i in range(5):
            conn = engine.connect()
            connections.append(conn)
            print(f"   Connection {i+1}: ‚úÖ Checked out")
        
        print(f"\nüìä Pool status after checkout:")
        print(f"   Checked out: {pool.checkedout()}")
        print(f"   Available: {pool.size() - pool.checkedout()}")
        
        # Clean up
        for conn in connections:
            conn.close()
        
        print(f"\nüìä Pool status after cleanup:")
        print(f"   Checked out: {pool.checkedout()}")
        print(f"   Available: {pool.size() - pool.checkedout()}")
        
        print("\n‚úÖ Connection pooling test PASSED")
        return True
    
    except Exception as e:
        print(f"\n‚ùå Connection pooling test FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_query_cache():
    """Test query caching functionality"""
    print("\n" + "=" * 60)
    print("Testing Query Cache")
    print("=" * 60)
    
    try:
        # Test cache availability
        if not analytics_cache.enabled:
            print("‚ö†Ô∏è  Query cache disabled (Redis not available)")
            return False
        
        print("\n‚úÖ Query cache enabled (Redis connected)")
        
        # Test basic cache operations
        test_key = "test_key"
        test_value = {"data": "test", "timestamp": time.time()}
        
        # Set
        print(f"\nüîÑ Testing cache SET...")
        success = analytics_cache.set(test_key, test_value, ttl=60)
        if success:
            print(f"   ‚úÖ Cache SET successful")
        else:
            print(f"   ‚ùå Cache SET failed")
            return False
        
        # Get
        print(f"\nüîÑ Testing cache GET...")
        cached = analytics_cache.get(test_key)
        if cached == test_value:
            print(f"   ‚úÖ Cache GET successful (value matches)")
        else:
            print(f"   ‚ùå Cache GET failed (value mismatch)")
            return False
        
        # Delete
        print(f"\nüîÑ Testing cache DELETE...")
        deleted = analytics_cache.delete(test_key)
        if deleted:
            print(f"   ‚úÖ Cache DELETE successful")
        else:
            print(f"   ‚ùå Cache DELETE failed")
            return False
        
        # Verify deleted
        cached_after = analytics_cache.get(test_key)
        if cached_after is None:
            print(f"   ‚úÖ Key successfully removed")
        else:
            print(f"   ‚ùå Key still exists after delete")
            return False
        
        # Test decorator caching
        print(f"\nüîÑ Testing decorator caching...")
        
        call_count = 0
        
        @analytics_cache.cached(ttl=60)
        def expensive_function(x: int):
            nonlocal call_count
            call_count += 1
            return x * 2
        
        # First call - should execute function
        result1 = expensive_function(5)
        print(f"   Call 1: result={result1}, call_count={call_count}")
        
        # Second call - should use cache
        result2 = expensive_function(5)
        print(f"   Call 2: result={result2}, call_count={call_count}")
        
        if call_count == 1 and result1 == result2 == 10:
            print(f"   ‚úÖ Decorator caching works (function called once)")
        else:
            print(f"   ‚ùå Decorator caching failed")
            return False
        
        # Test cache invalidation
        print(f"\nüîÑ Testing cache invalidation...")
        
        # Set multiple keys
        for i in range(5):
            analytics_cache.set(f"test_pattern:{i}", {"index": i})
        
        # Invalidate pattern
        deleted_count = analytics_cache.invalidate_pattern("test_pattern:*")
        print(f"   ‚úÖ Invalidated {deleted_count} keys")
        
        # Verify keys deleted
        remaining = analytics_cache.get("test_pattern:0")
        if remaining is None:
            print(f"   ‚úÖ Pattern invalidation successful")
        else:
            print(f"   ‚ùå Pattern invalidation failed")
            return False
        
        print("\n‚úÖ Query cache test PASSED")
        return True
    
    except Exception as e:
        print(f"\n‚ùå Query cache test FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_query_performance():
    """Test query performance with indexes"""
    print("\n" + "=" * 60)
    print("Testing Query Performance")
    print("=" * 60)
    
    try:
        db = SessionLocal()
        
        # Test 1: Social accounts lookup (uses idx_social_accounts_business_platform_active)
        print("\nüîÑ Test 1: Social accounts lookup")
        start = time.time()
        result = db.execute(text("""
            EXPLAIN ANALYZE
            SELECT * FROM social_accounts 
            WHERE business_id = 1 
            AND platform = 'linkedin' 
            AND is_active = true
        """))
        duration = (time.time() - start) * 1000
        
        plan = list(result)
        uses_index = any('idx_social_accounts_business_platform_active' in str(row) for row in plan)
        
        if uses_index:
            print(f"   ‚úÖ Uses index (query time: {duration:.2f}ms)")
        else:
            print(f"   ‚ö†Ô∏è  No index used (query time: {duration:.2f}ms)")
        
        # Test 2: Published posts by business (uses idx_published_posts_business_published_desc)
        print("\nüîÑ Test 2: Recent published posts")
        start = time.time()
        result = db.execute(text("""
            EXPLAIN ANALYZE
            SELECT * FROM published_posts 
            WHERE business_id = 1 
            ORDER BY published_at DESC 
            LIMIT 10
        """))
        duration = (time.time() - start) * 1000
        
        plan = list(result)
        uses_index = any('idx_published_posts_business_published_desc' in str(row) for row in plan)
        
        if uses_index:
            print(f"   ‚úÖ Uses index (query time: {duration:.2f}ms)")
        else:
            print(f"   ‚ö†Ô∏è  No index used (query time: {duration:.2f}ms)")
        
        db.close()
        
        print("\n‚úÖ Query performance test PASSED")
        return True
    
    except Exception as e:
        print(f"\n‚ùå Query performance test FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests"""
    print("\nüß™ DATABASE PERFORMANCE OPTIMIZATION TESTS\n")
    
    indexes_ok = test_indexes()
    pooling_ok = test_connection_pooling()
    cache_ok = test_query_cache()
    performance_ok = test_query_performance()
    
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    print(f"Database Indexes:     {'‚úÖ PASS' if indexes_ok else '‚ùå FAIL'}")
    print(f"Connection Pooling:   {'‚úÖ PASS' if pooling_ok else '‚ùå FAIL'}")
    print(f"Query Caching:        {'‚úÖ PASS' if cache_ok else '‚ö†Ô∏è  SKIPPED'}")
    print(f"Query Performance:    {'‚úÖ PASS' if performance_ok else '‚ùå FAIL'}")
    
    all_passed = indexes_ok and pooling_ok and performance_ok
    
    if all_passed:
        print("\nüéâ ALL TESTS PASSED!")
        print("\nüìà Performance Optimizations:")
        print("   ‚úÖ Database indexes for fast queries")
        print("   ‚úÖ Connection pooling (10 base + 20 overflow)")
        print("   ‚úÖ Query result caching (Redis-based)")
        print("   ‚úÖ Optimized query execution")
        return 0
    else:
        print("\n‚ö†Ô∏è  SOME TESTS FAILED")
        return 1


if __name__ == "__main__":
    sys.exit(main())
